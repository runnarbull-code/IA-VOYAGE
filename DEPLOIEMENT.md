# ğŸš€ Guide de DÃ©ploiement - Voyageur AI

Votre application est maintenant configurÃ©e pour utiliser l'API Ollama Cloud et peut Ãªtre dÃ©ployÃ©e facilement !

## ğŸ“‹ Modifications EffectuÃ©es

### âœ… Code Backend
- **pipeline.py** : Utilise maintenant l'API Ollama Cloud au lieu de l'installation locale
- **app.py** : Configure CORS et variables d'environnement pour le dÃ©ploiement
- **requirements.txt** : DÃ©pendances mises Ã  jour (requests, gunicorn, python-dotenv)

### âœ… Configuration
- **.env** : Stocke votre clÃ© API de maniÃ¨re sÃ©curisÃ©e (âš ï¸ NE PAS COMMITER)
- **.gitignore** : ProtÃ¨ge vos fichiers sensibles
- **Procfile** : Configuration pour Heroku
- **runtime.txt** : Version de Python

### âœ… Frontend
- **index_v2.html** : URL API dynamique (fonctionne en local ET en production)

---

## ğŸ”§ Test en Local

### 1. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 2. Configurer les variables d'environnement
Copiez `.env.example` vers `.env` et ajoutez votre clÃ© API :
```bash
OLLAMA_API_KEY=fc289982b86c43a8932b374295b7bd7b.fLzWxh3aqp2BQTPMo04iJzKT
```

### 3. Lancer le serveur
```bash
python app.py
```

### 4. Tester
Ouvrez http://localhost:5000 dans votre navigateur.

---

## ğŸŒ DÃ©ploiement sur Heroku

### PrÃ©requis
- Compte Heroku (gratuit) : https://signup.heroku.com/
- Heroku CLI installÃ© : https://devcenter.heroku.com/articles/heroku-cli

### Ã‰tape 1 : Initialiser Git
```bash
cd C:\Users\BoS\Desktop\llm\my-travel-itinerary-olama
git init
git add .
git commit -m "Initial commit - Voyageur AI"
```

### Ã‰tape 2 : CrÃ©er l'application Heroku
```bash
heroku login
heroku create voyageur-ai-app
```
*(Remplacez `voyageur-ai-app` par un nom unique)*

### Ã‰tape 3 : Configurer les variables d'environnement
```bash
heroku config:set OLLAMA_API_KEY=fc289982b86c43a8932b374295b7bd7b.fLzWxh3aqp2BQTPMo04iJzKT
heroku config:set OLLAMA_API_URL=https://api.ollama.cloud/v1/chat/completions
heroku config:set FLASK_ENV=production
```

### Ã‰tape 4 : DÃ©ployer
```bash
git push heroku main
```

### Ã‰tape 5 : Ouvrir l'application
```bash
heroku open
```

---

## ğŸš€ DÃ©ploiement sur Render

### Ã‰tape 1 : CrÃ©er un compte
Allez sur https://render.com et crÃ©ez un compte gratuit.

### Ã‰tape 2 : Nouveau Web Service
1. Cliquez sur "New +" â†’ "Web Service"
2. Connectez votre repository GitHub/GitLab
3. Ou utilisez "Public Git Repository" et entrez l'URL de votre repo

### Ã‰tape 3 : Configuration
- **Name** : `voyageur-ai`
- **Environment** : `Python`
- **Build Command** : `pip install -r requirements.txt`
- **Start Command** : `gunicorn app:app`

### Ã‰tape 4 : Variables d'environnement
Ajoutez dans "Environment Variables" :
```
OLLAMA_API_KEY = fc289982b86c43a8932b374295b7bd7b.fLzWxh3aqp2BQTPMo04iJzKT
OLLAMA_API_URL = https://api.ollama.cloud/v1/chat/completions
FLASK_ENV = production
```

### Ã‰tape 5 : DÃ©ployer
Cliquez sur "Create Web Service" et attendez le dÃ©ploiement !

---

## â˜ï¸ DÃ©ploiement sur Vercel

### Ã‰tape 1 : Installer Vercel CLI
```bash
npm install -g vercel
```

### Ã‰tape 2 : Se connecter
```bash
vercel login
```

### Ã‰tape 3 : DÃ©ployer
```bash
cd C:\Users\BoS\Desktop\llm\my-travel-itinerary-olama
vercel
```

### Ã‰tape 4 : Configurer les variables
```bash
vercel env add OLLAMA_API_KEY
# Entrez: fc289982b86c43a8932b374295b7bd7b.fLzWxh3aqp2BQTPMo04iJzKT

vercel env add OLLAMA_API_URL
# Entrez: https://api.ollama.cloud/v1/chat/completions
```

---

## ğŸ³ DÃ©ploiement avec Docker

### CrÃ©er un Dockerfile
```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 5000

CMD ["gunicorn", "--bind", "0.0.0.0:5000", "app:app"]
```

### Build et Run
```bash
docker build -t voyageur-ai .
docker run -p 5000:5000 \
  -e OLLAMA_API_KEY=fc289982b86c43a8932b374295b7bd7b.fLzWxh3aqp2BQTPMo04iJzKT \
  -e OLLAMA_API_URL=https://api.ollama.cloud/v1/chat/completions \
  voyageur-ai
```

---

## ğŸ”’ SÃ©curitÃ© - IMPORTANT

### âš ï¸ NE JAMAIS commiter le fichier .env
Le fichier `.gitignore` protÃ¨ge `.env`, mais vÃ©rifiez toujours :
```bash
git status
# .env ne doit PAS apparaÃ®tre
```

### âœ… Variables d'environnement en production
Toujours configurer les variables via :
- Heroku : `heroku config:set`
- Render : Dashboard â†’ Environment Variables
- Vercel : `vercel env add`

### ğŸ” Rotation de la clÃ© API
Si votre clÃ© est compromise :
1. GÃ©nÃ©rez une nouvelle clÃ© sur Ollama Cloud
2. Mettez Ã  jour les variables d'environnement
3. RedÃ©ployez l'application

---

## ğŸ“ Structure Finale

```
my-travel-itinerary-olama/
â”œâ”€â”€ app.py                    # Backend Flask
â”œâ”€â”€ pipeline.py               # Logique Ollama Cloud API
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”œâ”€â”€ Procfile                  # Configuration Heroku
â”œâ”€â”€ runtime.txt               # Version Python
â”œâ”€â”€ .env                      # Variables locales (âš ï¸ NE PAS COMMITER)
â”œâ”€â”€ .env.example              # Template de configuration
â”œâ”€â”€ .gitignore                # Fichiers Ã  ignorer
â””â”€â”€ static/
    â””â”€â”€ index.html            # Interface web (renommer index_v2.html)
```

---

## ğŸ§ª Tests Post-DÃ©ploiement

### Test 1 : SantÃ© de l'API
```bash
curl https://votre-app.herokuapp.com/api/health
```
RÃ©sultat attendu :
```json
{"status": "ok", "message": "API du gÃ©nÃ©rateur d'itinÃ©raires opÃ©rationnelle"}
```

### Test 2 : GÃ©nÃ©ration d'itinÃ©raire
```bash
curl -X POST https://votre-app.herokuapp.com/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "destination": "Paris",
    "duration": 3,
    "interests": ["art", "food"],
    "budget": 1500
  }'
```

### Test 3 : Interface Web
Ouvrez `https://votre-app.herokuapp.com` et testez la gÃ©nÃ©ration.

---

## ğŸ› DÃ©pannage

### Erreur : "API Key not configured"
- VÃ©rifiez que `OLLAMA_API_KEY` est bien dÃ©finie
- Relancez le serveur aprÃ¨s modification du .env

### Erreur 500 sur l'API
- VÃ©rifiez les logs : `heroku logs --tail`
- Testez l'API Ollama directement
- VÃ©rifiez la validitÃ© de votre clÃ© API

### L'application ne se charge pas
- VÃ©rifiez que `static/index.html` existe
- Assurez-vous que tous les fichiers sont commitÃ©s

### Timeout lors de la gÃ©nÃ©ration
- Normal pour les premiÃ¨res requÃªtes
- Ajustez le timeout si nÃ©cessaire dans `pipeline.py`

---

## ğŸ“Š Monitoring

### Heroku
```bash
heroku logs --tail
heroku ps
```

### Render
Dashboard â†’ Logs

### Localement
Les logs s'affichent dans le terminal oÃ¹ vous avez lancÃ© `python app.py`

---

## ğŸ’° CoÃ»ts

### API Ollama Cloud
- VÃ©rifiez votre plan sur https://ollama.cloud/pricing
- Surveillez votre usage

### HÃ©bergement
- **Heroku** : Plan gratuit disponible (limitÃ©)
- **Render** : Plan gratuit disponible
- **Vercel** : Plan gratuit pour les projets personnels

---

## ğŸ‰ Votre Application est PrÃªte !

Votre gÃ©nÃ©rateur d'itinÃ©raires fonctionne maintenant avec l'API Ollama Cloud et peut Ãªtre dÃ©ployÃ© sur n'importe quelle plateforme !

### Checklist Finale
- [ ] Tests en local fonctionnent
- [ ] `.env` est dans `.gitignore`
- [ ] Variables d'environnement configurÃ©es en production
- [ ] Application dÃ©ployÃ©e et accessible
- [ ] Tests post-dÃ©ploiement effectuÃ©s

**Bon dÃ©ploiement ! ğŸš€âœˆï¸**
